{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Movie Review Binary Sentiment Classification\n",
    "\n",
    "This movie review data comes from http://www.cs.cornell.edu/people/pabo/movie-review-data/ and the sentiment work done by Pang and Lee."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# necessary imports\n",
    "from os.path import isfile\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from toal.stores import BasicStore\n",
    "from toal.stores.loaders import load_split_multi_label_csv\n",
    "from toal.learners import BinaryLearner\n",
    "from toal.samplers import BinaryUncertaintySampler, RandomSampler, BinaryDensitySampler\n",
    "from toal.evaluators import F1Evaluator\n",
    "from toal.annotators import SimulatedAnnotator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_movie_review_data():\n",
    "    # TODO\n",
    "    print(\"Not implemented yet!\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data and store in CSV\n",
    "if not isfile('../data/mr.csv'):\n",
    "    download_movie_review_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using default encoders, same of writing BasicStore(extractor=TfIdfExtractor(), encoder=GenericLabelBinarizer())\n",
    "store = BasicStore()\n",
    "labeled_df, unlabeled_df, unlabeled_map = load_split_multi_label_csv('../data/mr.csv', shuffle=True)\n",
    "store.append_data( labeled_df, unlabeled_df )\n",
    "\n",
    "learner = BinaryLearner()\n",
    "sampler = BinaryUncertaintySampler(learner)\n",
    "annotator = SimulatedAnnotator(unlabeled_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate initial model on training subset (20% of data)\n",
    "model = learner.train(store)\n",
    "\n",
    "train_inst_count = []\n",
    "f1s = []\n",
    "f1evaluator = F1Evaluator()\n",
    "f1 = f1evaluator.evaluate(model, *store.test_XYs)\n",
    "f1s.append(f1)\n",
    "print(f\"Multiclass learner F1 evaluation score is {f1}\")\n",
    "train_inst_count.append(store.train_XYs[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while not store.unlabeled_df.empty:\n",
    "#for i in range(10):\n",
    "    # sample and annotate new data\n",
    "    unlabeled_selection = sampler.choose_instances(store, batch_size=50)\n",
    "    annotated_df = annotator.annotate(unlabeled_selection, store.available_labels)\n",
    "    store.update_with_annotation(annotated_df)\n",
    "\n",
    "    # retrain with newly labeled data\n",
    "    model = learner.train(store)\n",
    "\n",
    "    # evaluate\n",
    "    f1 = f1evaluator.evaluate(model, *store.test_XYs)\n",
    "    f1s.append(f1)\n",
    "    train_inst_count.append(store.train_XYs[0].shape[0])  # get rows in X\n",
    "    print(f\"Multiclass learner F1 evaluation score is {f1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# random sampling for comparison\n",
    "random_store = BasicStore()\n",
    "labeled_df, unlabeled_df, unlabeled_map = load_split_multi_label_csv('../data/mr.csv', shuffle=True)\n",
    "random_store.append_data( labeled_df, unlabeled_df )\n",
    "\n",
    "learner = BinaryLearner()\n",
    "sampler = RandomSampler()\n",
    "\n",
    "annotator = SimulatedAnnotator(unlabeled_map)\n",
    "\n",
    "model = learner.train(random_store)\n",
    "\n",
    "random_f1s = []\n",
    "f1evaluator = F1Evaluator()\n",
    "f1 = f1evaluator.evaluate(model, *random_store.test_XYs)\n",
    "random_f1s.append(f1)\n",
    "\n",
    "while not random_store.unlabeled_df.empty:\n",
    "    # sample and annotate new data\n",
    "    unlabeled_selection = sampler.choose_instances(random_store, batch_size=50)\n",
    "    annotated_df = annotator.annotate(unlabeled_selection, random_store.available_labels)\n",
    "    random_store.update_with_annotation(annotated_df)\n",
    "\n",
    "    # retrain with newly labeled data\n",
    "    model = learner.train(random_store)\n",
    "\n",
    "    # evaluate\n",
    "    f1 = f1evaluator.evaluate(model, *random_store.test_XYs)\n",
    "    random_f1s.append(f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_inst_count, random_f1s, 'g-', label=\"Random sampling\")\n",
    "plt.plot(train_inst_count, f1s, 'r-', label=\"Uncertainty sampling\")\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel(\"F1 (macro)\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sampler(sampler, batch_size):\n",
    "    store = BasicStore()\n",
    "    labeled_df, unlabeled_df, unlabeled_map = load_split_multi_label_csv('../data/mr.csv', shuffle=True)\n",
    "    store.append_data( labeled_df, unlabeled_df )\n",
    "\n",
    "    learner = BinaryLearner()\n",
    "    annotator = SimulatedAnnotator(unlabeled_map)\n",
    "\n",
    "    model = learner.train(store)\n",
    "\n",
    "    f1s = []\n",
    "    f1evaluator = F1Evaluator()\n",
    "    f1 = f1evaluator.evaluate(model, *store.test_XYs)\n",
    "    f1s.append(f1)\n",
    "\n",
    "    while not store.unlabeled_df.empty:\n",
    "        # sample and annotate new data\n",
    "        unlabeled_selection = sampler.choose_instances(store, batch_size=batch_size)\n",
    "        annotated_df = annotator.annotate(unlabeled_selection, store.available_labels)\n",
    "        store.update_with_annotation(annotated_df)\n",
    "\n",
    "        # retrain with newly labeled data\n",
    "        model = learner.train(store)\n",
    "\n",
    "        # evaluate\n",
    "        f1 = f1evaluator.evaluate(model, *store.test_XYs)\n",
    "        f1s.append(f1)\n",
    "        \n",
    "    return f1s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_f1s = test_sampler(BinaryUncertaintySampler(learner, strategy='lc'), 50)\n",
    "ms_f1s = test_sampler(BinaryUncertaintySampler(learner, strategy='ms'), 50)\n",
    "dw_f1s = test_sampler(BinaryDensitySampler(learner, strategy='ent', beta=1), 50)\n",
    "dw2_f1s = test_sampler(BinaryDensitySampler(learner, strategy='ent', beta=2), 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(train_inst_count, random_f1s, 'g-', label=\"Random sampling\")\n",
    "plt.plot(train_inst_count, f1s, 'c:', label=\"Uncertainty sampling (ent)\")\n",
    "plt.plot(train_inst_count, lc_f1s, 'r-', label=\"Uncertainty sampling (lc)\")\n",
    "plt.plot(train_inst_count, ms_f1s, 'm-.', label=\"Uncertainty sampling (ms)\")\n",
    "plt.plot(train_inst_count, dw_f1s, 'y-.', label=\"Density weighted\")\n",
    "plt.plot(train_inst_count, dw2_f1s, 'b-.', label=\"Density weighted (2)\")\n",
    "plt.xlabel('Training Size')\n",
    "plt.ylabel(\"F1 (macro)\")\n",
    "plt.legend(loc='best')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
